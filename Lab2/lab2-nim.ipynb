{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive(state: Nim) -> Nimply:\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    genome = {\"love_small\": 0.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7 9>\n",
      "INFO:root:ply: player 0 plays Nimply(row=1, num_objects=2)\n",
      "INFO:root:status: <1 1 5 7 9>\n",
      "INFO:root:ply: player 1 plays Nimply(row=1, num_objects=1)\n",
      "INFO:root:status: <1 0 5 7 9>\n",
      "INFO:root:ply: player 0 plays Nimply(row=4, num_objects=5)\n",
      "INFO:root:status: <1 0 5 7 4>\n",
      "INFO:root:ply: player 1 plays Nimply(row=4, num_objects=4)\n",
      "INFO:root:status: <1 0 5 7 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=2, num_objects=5)\n",
      "INFO:root:status: <1 0 0 7 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=0, num_objects=1)\n",
      "INFO:root:status: <0 0 0 7 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=3, num_objects=4)\n",
      "INFO:root:status: <0 0 0 3 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=3, num_objects=1)\n",
      "INFO:root:status: <0 0 0 2 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=3, num_objects=1)\n",
      "INFO:root:status: <0 0 0 1 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=3, num_objects=1)\n",
      "INFO:root:status: <0 0 0 0 0>\n",
      "INFO:root:status: Player 0 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "strategy = (optimal, pure_random)\n",
    "\n",
    "nim = Nim(5)\n",
    "logging.info(f\"init : {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    logging.info(f\"ply: player {player} plays {ply}\")\n",
    "    nim.nimming(ply)\n",
    "    logging.info(f\"status: {nim}\")\n",
    "    player = 1 - player\n",
    "logging.info(f\"status: Player {player} won!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import List, Tuple, Optional, Callable, Union\n",
    "from itertools import chain, combinations\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, num_rows: int, params: Optional[np.array] = None, k: Optional[int] = None) -> None:\n",
    "        \"\"\"\n",
    "        num_rows: number of rows of the game\n",
    "        params: initial parameters\n",
    "        k: largest number of piles it can take\n",
    "        \"\"\"\n",
    "        if params is None:\n",
    "            self._params = np.random.normal(size=num_rows)\n",
    "        else:\n",
    "            self._params = params\n",
    "        if k is None:\n",
    "            self.k = (2*num_rows)-1\n",
    "        else:\n",
    "            self.k = k\n",
    "        self.fitness_scores: List[float] = []\n",
    "        self.num_rows = num_rows\n",
    "\n",
    "    def powerset(self, iterable): # utility for an attempt of a more sophistacated but unsuccessful strategy\n",
    "        s = list(iterable)\n",
    "        return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "    \n",
    "    def binary_matrix_from_array(self, arr):\n",
    "        binary_matrix = [list(map(lambda x: -1 if x == '0' else 1, bin(num)[2:].zfill(self.num_rows))) for num in arr]\n",
    "        return np.array(binary_matrix)\n",
    "    \n",
    "    def powerset_matrix(self,arr): # utility for an attempt of a more sophistacated but unsuccessful strategy\n",
    "        binary_matrix = list(self.binary_matrix_from_array(arr).T)\n",
    "        res = []\n",
    "        for row in binary_matrix:\n",
    "            pset = self.powerset(row)\n",
    "            pset.pop(0)\n",
    "            res.append(list(map(lambda x: reduce(lambda v1, v2: int(v1*v2),x), pset)))\n",
    "        return np.array(res)\n",
    "    \n",
    "    def __lt__(self, other: 'Agent'):\n",
    "        return self.fitness < other.fitness\n",
    "\n",
    "    def strategy(self, nim: Nim) -> Nimply:\n",
    "        possible_moves: List[Tuple[float, Nimply]] = self.generate_states(nim)\n",
    "        best: Nimply = max(possible_moves, key = lambda v: v[0])[1]\n",
    "        return best\n",
    "\n",
    "    def generate_states(self, nim: Nim) -> List[Tuple[float, Nimply]]:\n",
    "        ply_list: List[float, Nimply] = []\n",
    "        for ply in (Nimply(r, o) for r, c in enumerate(nim.rows) for o in range(1, c + 1)):\n",
    "            tmp: Nim = deepcopy(nim)\n",
    "            tmp.nimming(ply)\n",
    "            n_more_than_one: int = 0\n",
    "            for r in tmp.rows:\n",
    "                if r>1:\n",
    "                    n_more_than_one += 1\n",
    "            score: float = np.average(self._params @ self.binary_matrix_from_array(tmp.rows))    \n",
    "            ply_list.append((score, ply))\n",
    "        return ply_list\n",
    "            \n",
    "\n",
    "    def analize(self, raw: Nim) -> dict:\n",
    "        cooked = dict()\n",
    "        cooked[\"possible_moves\"] = dict()\n",
    "        for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, min(self.k, c + 1))):\n",
    "            tmp = deepcopy(raw)\n",
    "            tmp.nimming(ply)\n",
    "            cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "        return cooked\n",
    "    \n",
    "    @property\n",
    "    def params(self):\n",
    "        return self._params\n",
    "\n",
    "    @params.setter\n",
    "    def params(self, p):\n",
    "        self._params = p\n",
    "    \n",
    "    @property\n",
    "    def fitness(self):\n",
    "        if len(self.fitness_scores) > 0:\n",
    "            return np.mean(self.fitness_scores)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    @fitness.setter\n",
    "    def fitness(self, fitness: float):\n",
    "        self.fitness_scores.append(fitness)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.fitness_scores = []\n",
    "    \n",
    "    def __iadd__(self, other) -> None:\n",
    "        self._params += other\n",
    "\n",
    "\n",
    "class EvolutionTask:\n",
    "\n",
    "    def __init__(self, num_rows: int, k: Optional[int] = None, scale: float = 1.0, loc: float = 0.0, strategy='comma', mu=25, population_size=50) -> None:\n",
    "        if k is None:\n",
    "            self.k = 2*num_rows-1\n",
    "        else:\n",
    "            self.k = k\n",
    "        self.scale = scale\n",
    "        self.loc = loc\n",
    "        self.num_rows = num_rows\n",
    "        self.mu = mu\n",
    "        self.strategy = strategy\n",
    "        self.population_size = population_size\n",
    "    \n",
    "    def mutate(self, agent: Agent) -> None:\n",
    "        \"\"\"\n",
    "        Mutates according to Gaussian mutation\n",
    "        \"\"\"\n",
    "        agent.params += np.random.normal(size = agent.params.shape, loc=self.loc, scale=self.scale)\n",
    "\n",
    "    def play_match(self, a1: Agent, a2: Agent) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Play match between two agents\n",
    "        The fitness of the game for one agent is given by the percentage of optimal moves it performs\n",
    "        An optimal move is decided as written in https://en.wikipedia.org/wiki/Nim\n",
    "        \"\"\"\n",
    "        correct_moves_count: List[int, int] = [0, 0]\n",
    "        optimal_is_possible_count: List[int, int] = [0, 0]\n",
    "\n",
    "        strategy: Tuple[Callable, Callable] = (a1.strategy, a2.strategy)\n",
    "\n",
    "        nim: Nim = Nim(self.num_rows)\n",
    "        optimal_nimsum: Optional[int] = 0\n",
    "        played_optimal: bool = True\n",
    "        player = 0\n",
    "        while nim:\n",
    "            ply = strategy[player](nim)\n",
    "            if self.is_late_state(nim):\n",
    "                if self.nim_sum(nim) == 0:\n",
    "                    optimal_nimsum = 1\n",
    "                    optimal_is_possible_count[player] += 1\n",
    "                else:\n",
    "                    optimal_nimsum = None\n",
    "            else:\n",
    "                if self.nim_sum(nim) > 0:\n",
    "                    optimal_nimsum = 0\n",
    "                    optimal_is_possible_count[player] += 1\n",
    "                else:\n",
    "                    optimal_nimsum = None\n",
    "            nim.nimming(ply)\n",
    "            if optimal_nimsum is not None:\n",
    "                played_optimal = self.nim_sum(nim) == optimal_nimsum\n",
    "            if played_optimal:\n",
    "                correct_moves_count[player] += 1\n",
    "            player = 1 - player\n",
    "        \n",
    "        fitness: List[float, float] = [0,0]\n",
    "\n",
    "        for player in [0,1]:\n",
    "            if optimal_is_possible_count[player] == 0:\n",
    "                fitness[player] = 0\n",
    "            else:\n",
    "                fitness[player] = correct_moves_count[player]/optimal_is_possible_count[player]\n",
    "\n",
    "        return fitness\n",
    "    \n",
    "    def is_late_state(self, nim: Nim):\n",
    "        \"\"\"\n",
    "        Verifies whether we are in the late stages of the game, that is where we have at most one row with two or more piles\n",
    "        \"\"\"\n",
    "        n_rows_with_multiple_piles: int = 0\n",
    "        for row in nim.rows:\n",
    "            if row>=2:\n",
    "                n_rows_with_multiple_piles += 1\n",
    "        return n_rows_with_multiple_piles < 2\n",
    "    \n",
    "    def tournament(self, size: Union[int, float]):\n",
    "        \"\"\"\n",
    "        Do random matches to calculate fitness\n",
    "        \"\"\"\n",
    "        if isinstance(size, float):\n",
    "            size = int(size*self.population_size)\n",
    "        matches = np.random.choice(self.agents, size=(size,2))\n",
    "        for a1, a2 in matches:\n",
    "            f1, f2 = self.play_match(a1, a2)\n",
    "            a1.fitness = f1\n",
    "            a2.fitness = f2\n",
    "\n",
    "    def nim_sum(self, state: Nim) -> int:\n",
    "        \"\"\"\n",
    "        Calculate the nim sum of a state\n",
    "        \"\"\"\n",
    "        tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "        xor = tmp.sum(axis=0) % 2\n",
    "        return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "    \n",
    "    def exploration(self, tournament_size = 10.0) -> None:\n",
    "        \"\"\"\n",
    "        Performs tournament to calculate fitness and select parents\n",
    "        \"\"\"\n",
    "        self.tournament(tournament_size)\n",
    "        mu = self.mu\n",
    "        parents = np.partition(self.agents, self.population_size-mu)[self.population_size-mu:] # takes the top half parents in terms of fitness\n",
    "        children = []\n",
    "        if self.strategy == 'comma':\n",
    "            num_children = self.population_size\n",
    "        else:\n",
    "            num_children = self.population_size-mu\n",
    "        for _ in range(num_children):\n",
    "            children.append(self.crossover(np.random.choice(parents), np.random.choice(parents)))\n",
    "        \"\"\"for _ in range(2):\n",
    "            random_indices = np.random.choice(mu, size=mu, replace=False) # randomly select two parents \n",
    "            for i in range(len(random_indices)//2):\n",
    "                children.append(self.crossover(parents[random_indices[i]], parents[random_indices[(len(random_indices)//2+i)%(len(random_indices))]]))\"\"\"\n",
    "        if self.strategy == 'comma':\n",
    "            self.agents = np.array(children)\n",
    "        else:\n",
    "            num_children = self.population_size-mu\n",
    "        self.agents = np.concatenate((parents,children))\n",
    "    \n",
    "    def crossover(self, a1: Agent, a2: Agent) -> Agent:\n",
    "        \"\"\"\n",
    "        Given two agents it randomly selects the parameters between the two\n",
    "        \"\"\"\n",
    "        new_params: List[float] = []\n",
    "        for i in range(len(a1.params)):\n",
    "            if np.random.normal() > 0:\n",
    "                new_params.append(a1.params[i])\n",
    "            else:\n",
    "                new_params.append(a2.params[i])\n",
    "        return Agent(self.num_rows, np.array(new_params), self.k)        \n",
    "\n",
    "\n",
    "    def exploitation(self, tournament_size = 10.0) -> None:\n",
    "        \"\"\"\n",
    "        Mutates parameters of the agents with Gaussian mutation\n",
    "        \"\"\"\n",
    "        self.tournament(tournament_size)\n",
    "        mu = self.mu\n",
    "        parents = np.partition(self.agents, self.population_size-mu)[self.population_size-mu:] # takes the top half parents in terms of fitness\n",
    "        children = []\n",
    "        if self.strategy == 'comma':\n",
    "            num_children = self.population_size\n",
    "        else:\n",
    "            num_children = self.population_size-mu\n",
    "        for _ in range(num_children):\n",
    "            children.append(self.mutate(np.random.choice(parents)))\n",
    "\n",
    "        \"\"\"for a in self.agents:\n",
    "            self.mutate(a)\"\"\"\n",
    "    \n",
    "    def reset_fitness(self) -> None:\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def train(self, n_generations=100, tournament_size=10.0, temperature = 0.5):\n",
    "        \"\"\"\n",
    "        Training loop, the temperature defines the transition from an exploration prevalent strategy to an exploitation prevalent strategy.\n",
    "        In particular exploitation is performed with probability P[X>(generation/tot_generations)^t], while exploitation is performed with P[X<(generation/tot_generations)^t], where X is uniformly distributed between 0 and 1\n",
    "        \"\"\"\n",
    "        self.agents: List[Agent] = [Agent(self.num_rows, k=self.k) for _ in range(self.population_size)]\n",
    "        self.best_agent = None\n",
    "        for gen in tqdm(range(n_generations)):\n",
    "            if np.random.uniform(0,1) < np.power(gen/n_generations, temperature):\n",
    "                #exploitation\n",
    "                self.exploitation()\n",
    "            if np.random.uniform(0,1) > np.power(gen/n_generations, temperature):\n",
    "                #exploration\n",
    "                self.exploration(tournament_size=tournament_size)\n",
    "            self.best_agent = max(self.agents, key = lambda x: x.fitness)\n",
    "            self.reset_fitness()\n",
    "    \n",
    "    @property\n",
    "    def best_agent(self) -> Agent:\n",
    "        return self._best_agent\n",
    "\n",
    "    @best_agent.setter\n",
    "    def best_agent(self, a: Optional[Agent]) -> Agent:\n",
    "        self._best_agent = a\n",
    "    \n",
    "    def test_best_agent(self, expert_strategy: Callable[[Nim, Nimply], None], num_matches=100):\n",
    "        strategy = (self.best_agent.strategy, expert_strategy)\n",
    "        wins = 0\n",
    "        for _ in range(num_matches):\n",
    "            nim = Nim(self.num_rows)\n",
    "            player = 0\n",
    "            while nim:\n",
    "                ply = strategy[player](nim)\n",
    "                nim.nimming(ply)\n",
    "                player = 1 - player\n",
    "            if player==0:\n",
    "                wins += 1\n",
    "        logging.info(f\"status: best agent won {100*wins/num_matches}% of times\")\n",
    "\n",
    "class AgentDict:\n",
    "\n",
    "    \"\"\"\n",
    "    Class for storing rule based agents\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k: Optional[int] = None) -> None:\n",
    "        self.k = k\n",
    "    \n",
    "    def pure_random(self, state: Nim) -> Nimply:\n",
    "        \"\"\"A completely random move\"\"\"\n",
    "        if self.k is None:\n",
    "            self.k = len(state.rows)*2-1\n",
    "        row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "        num_objects = random.randint(1, min(self.k, state.rows[row]))\n",
    "        return Nimply(row, num_objects)\n",
    "\n",
    "    def gabriele(self, state: Nim) -> Nimply:\n",
    "        \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "        if self.k is None:\n",
    "            self.k = len(state.rows)*2-1\n",
    "        possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "        return Nimply(*max(possible_moves, key=lambda m: (-m[0], min(self.k, m[1]))))\n",
    "    \n",
    "\n",
    "    def nim_sum(self, state: Nim) -> int:\n",
    "        tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "        xor = tmp.sum(axis=0) % 2\n",
    "        return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "    def analize(self, raw: Nim) -> dict:\n",
    "        cooked = dict()\n",
    "        cooked[\"possible_moves\"] = dict()\n",
    "        for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, min(self.k, c + 1))):\n",
    "            tmp = deepcopy(raw)\n",
    "            tmp.nimming(ply)\n",
    "            cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "        return cooked\n",
    "\n",
    "\n",
    "    def optimal(self, state: Nim) -> Nimply:\n",
    "        analysis = analize(state)\n",
    "        logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "        spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "        if not spicy_moves:\n",
    "            spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "        ply = random.choice(spicy_moves)\n",
    "        return ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:35<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "et = EvolutionTask(3, mu=25, population_size=50, strategy='comma')\n",
    "et.train(n_generations=100, temperature=0.5, tournament_size=2.0)\n",
    "a: Agent = et.best_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:status: best agent won 57.6% of times\n"
     ]
    }
   ],
   "source": [
    "agent_dict = AgentDict()\n",
    "\n",
    "et.test_best_agent(agent_dict.pure_random, num_matches=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
